# jobs/scheduler.py
import schedule, time
from datetime import datetime
from jobs.sqlite_loader import load_topic_to_sqlite
from jobs.cleanup import clean_old_data
from jobs.permissions_manager import init_permissions_table, list_permissions
from config.settings import DATA_LAKE_PATH


def orchestrate():
    print(f"\n‚öôÔ∏è [{datetime.now()}] D√âBUT DU PIPELINE : Kafka ‚Üí Data Lake ‚Üí SQLite")

    # V√©rifie la gouvernance
    init_permissions_table()
    permissions = list_permissions()
    print(f"üîê Permissions actuelles ({len(permissions)}): {permissions}")

    # Ingestion Data Lake ‚Üí SQLite
    topics = [
        "TRANSACTIONS_SECURE", "TRANSACTIONS_USD",
        "USER_SPENDING_BY_TYPE", "SPEND_LAST_FIVE_MIN_BY_TYPE",
        "TRANSACTIONS_BLACKLISTED", "TRANSACTIONS_COMPLETED",
        "TRANSACTIONS_FAILED", "TRANSACTIONS_PENDING", "TRANSACTIONS_PROCESSING"
    ]

    for topic in topics:
        try:
            load_topic_to_sqlite(topic)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sur {topic}: {e}")

    # Nettoyage des anciens fichiers
    clean_old_data(days=7)

    print("‚úÖ Pipeline ex√©cut√© avec succ√®s.\n")


def main():
    orchestrate()  # premi√®re ex√©cution imm√©diate
    schedule.every(10).minutes.do(orchestrate)
    print("üïê Scheduler actif ‚Äî pipeline toutes les 10 minutes.")

    while True:
        schedule.run_pending()
        time.sleep(60)


if __name__ == "__main__":
    main()
